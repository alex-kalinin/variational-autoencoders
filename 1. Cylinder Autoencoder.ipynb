{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf images/_cylinders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:00:35.647031Z",
     "iopub.status.busy": "2022-10-05T21:00:35.646304Z",
     "iopub.status.idle": "2022-10-05T21:00:35.700666Z",
     "shell.execute_reply": "2022-10-05T21:00:35.699686Z",
     "shell.execute_reply.started": "2022-10-05T21:00:35.646925Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytroch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:00:39.144878Z",
     "iopub.status.busy": "2022-10-05T21:00:39.144563Z",
     "iopub.status.idle": "2022-10-05T21:00:41.563466Z",
     "shell.execute_reply": "2022-10-05T21:00:41.562329Z",
     "shell.execute_reply.started": "2022-10-05T21:00:39.144854Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy and charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:00:57.657674Z",
     "iopub.status.busy": "2022-10-05T21:00:57.657098Z",
     "iopub.status.idle": "2022-10-05T21:00:57.663068Z",
     "shell.execute_reply": "2022-10-05T21:00:57.662330Z",
     "shell.execute_reply.started": "2022-10-05T21:00:57.657645Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T20:51:52.995824Z",
     "iopub.status.busy": "2022-10-05T20:51:52.994438Z",
     "iopub.status.idle": "2022-10-05T20:51:53.003444Z",
     "shell.execute_reply": "2022-10-05T20:51:53.001197Z",
     "shell.execute_reply.started": "2022-10-05T20:51:52.995775Z"
    }
   },
   "source": [
    "We will keep variables inside an object to not pollute the global namespace, and prevent various bugs. The class defined as follows allows adding attributes at runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:01:00.203493Z",
     "iopub.status.busy": "2022-10-05T21:01:00.203159Z",
     "iopub.status.idle": "2022-10-05T21:01:00.208532Z",
     "shell.execute_reply": "2022-10-05T21:01:00.207521Z",
     "shell.execute_reply.started": "2022-10-05T21:01:00.203468Z"
    }
   },
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "# Will contain all our variables\n",
    "t = Object()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare - Generate Cylinder Images\n",
    "\n",
    "The code below generates cylinder images that we will use for training. We don't use this code directly anywhere else. You can pre-generate images, save them, and use the training part separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-05T21:01:02.989435Z",
     "iopub.status.busy": "2022-10-05T21:01:02.989097Z",
     "iopub.status.idle": "2022-10-05T21:01:03.648979Z",
     "shell.execute_reply": "2022-10-05T21:01:03.647675Z",
     "shell.execute_reply.started": "2022-10-05T21:01:02.989411Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageContainer:\n",
    "    def __init__(self, image: Image, wh: Tuple[int, int]):\n",
    "        self.image = image\n",
    "        self.wh = wh\n",
    "        \n",
    "    def save_to_dir(self, image_dir, image_index):\n",
    "        w, h = self.wh\n",
    "        save_path = f\"{image_dir}/image_{image_index}_{w}_{h}.png\"\n",
    "        self.image.save(save_path, cmap=\"gray\")\n",
    "        \n",
    "    def get_image(self) -> Image:\n",
    "        return self.image\n",
    "  \n",
    "def draw_cylinder(wh: tuple, image_size) -> ImageContainer: \n",
    "    w, h = wh\n",
    "    background_color = 0\n",
    "    figure_color = 200\n",
    "    line_thickness = 2\n",
    "    ellipse_h = 10 # int(min(image_size / 6, h / 3))\n",
    "    im = Image.new(\"L\", (image_size, image_size))\n",
    "    \n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.rectangle([0, 0, im.size[0], im.size[1]], \n",
    "                   fill=background_color,\n",
    "                   outline=figure_color)\n",
    "    \n",
    "    # Calculate offsets when drawing a bounding rectangle\n",
    "    im_w, im_h = im.size \n",
    "    x_offset = (im_w - w) / 2\n",
    "    y_offset = (im_h - h) / 2\n",
    "\n",
    "    # Sides\n",
    "    draw.line([x_offset, y_offset, x_offset, y_offset + h], width=line_thickness, fill=figure_color)\n",
    "    draw.line([x_offset + w, y_offset, x_offset + w, y_offset + h], width=line_thickness, fill=figure_color)\n",
    "    \n",
    "    \n",
    "    # top ellipse\n",
    "    draw.ellipse([\n",
    "        x_offset, \n",
    "        y_offset - ellipse_h / 2,\n",
    "        x_offset + w,\n",
    "        y_offset + ellipse_h / 2], \n",
    "        width=line_thickness,\n",
    "        outline=figure_color)\n",
    "    \n",
    "    # bottom ellipse\n",
    "    draw.ellipse([\n",
    "        x_offset, \n",
    "        y_offset - ellipse_h / 2 + h,\n",
    "        x_offset + w,\n",
    "        y_offset + ellipse_h / 2 + h], \n",
    "        width=line_thickness,\n",
    "        outline=figure_color)\n",
    "    \n",
    "    # hide the back side of the bottom ellipse\n",
    "    draw.rectangle([\n",
    "        x_offset + line_thickness , \n",
    "        y_offset - ellipse_h / 2 + h,\n",
    "        x_offset + w - line_thickness + 1,\n",
    "        y_offset + h], \n",
    "        fill=background_color, \n",
    "        width=line_thickness)\n",
    "    \n",
    "    return ImageContainer(im, wh)\n",
    "#------------------------------------------------------------------------------------\n",
    "def generate_cylinders(count, w_range, h_range, image_size) -> List[ImageContainer]:\n",
    "    images = []\n",
    "    for w in range(w_range[0], w_range[1] + 1):\n",
    "        for h in range(h_range[0], h_range[1] + 1):\n",
    "            images.append(draw_cylinder((w, h), image_size))\n",
    "    random.shuffle(images)\n",
    "    return images[0:count]\n",
    "#------------------------------------------------------------------------------------\n",
    "def save_images(output_folder, images):\n",
    "    for i, img in enumerate(images):\n",
    "        img.save_to_dir(output_folder, i)\n",
    "#------------------------------------------------------------------------------------\n",
    "t.image_size = 64\n",
    "dirs = \"images/_cylinders\"\n",
    "os.makedirs(dirs, exist_ok=True)\n",
    "min_size = 14\n",
    "max_size = 50\n",
    "images = generate_cylinders(1000, (min_size, max_size), (min_size, max_size), t.image_size)\n",
    "save_images(\"images/_cylinders\", images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Device, GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:59.042840Z",
     "iopub.status.busy": "2022-10-05T21:40:59.042527Z",
     "iopub.status.idle": "2022-10-05T21:40:59.051177Z",
     "shell.execute_reply": "2022-10-05T21:40:59.049794Z",
     "shell.execute_reply.started": "2022-10-05T21:40:59.042816Z"
    }
   },
   "outputs": [],
   "source": [
    "t.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "t.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ToTensor` is a function from the `transforms` package that converts numpy arrays to Pytorch Tensors. During the conversion it performs a few operations:\n",
    "\n",
    "1. Changes order of dimensions from numpy's Height x Width x Channel to C x H x W.\n",
    "2. Rescales [0, 255] to [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:03.144221Z",
     "iopub.status.busy": "2022-10-05T21:40:03.143885Z",
     "iopub.status.idle": "2022-10-05T21:40:03.150209Z",
     "shell.execute_reply": "2022-10-05T21:40:03.149135Z",
     "shell.execute_reply.started": "2022-10-05T21:40:03.144195Z"
    }
   },
   "outputs": [],
   "source": [
    "t.to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of our images (see the code above to find out this location):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:01.193762Z",
     "iopub.status.busy": "2022-10-05T21:40:01.193335Z",
     "iopub.status.idle": "2022-10-05T21:40:01.199677Z",
     "shell.execute_reply": "2022-10-05T21:40:01.197834Z",
     "shell.execute_reply.started": "2022-10-05T21:40:01.193735Z"
    }
   },
   "outputs": [],
   "source": [
    "t.image_folder = \"images/_cylinders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:03.471571Z",
     "iopub.status.busy": "2022-10-05T21:40:03.471238Z",
     "iopub.status.idle": "2022-10-05T21:40:03.477956Z",
     "shell.execute_reply": "2022-10-05T21:40:03.476715Z",
     "shell.execute_reply.started": "2022-10-05T21:40:03.471547Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_images(folder):\n",
    "    images = []\n",
    "    image_tensors = []\n",
    "    for fname in os.listdir(folder):\n",
    "        image_path = f\"{folder}/{fname}\"\n",
    "        im = Image.open(image_path).convert(\"L\")\n",
    "        np_im = np.asarray(im)\n",
    "        images.append(np_im)\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:04.963633Z",
     "iopub.status.busy": "2022-10-05T21:40:04.963213Z",
     "iopub.status.idle": "2022-10-05T21:40:05.125461Z",
     "shell.execute_reply": "2022-10-05T21:40:05.124123Z",
     "shell.execute_reply.started": "2022-10-05T21:40:04.963605Z"
    }
   },
   "outputs": [],
   "source": [
    "t.images = read_images(t.image_folder)\n",
    "t.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll this function to display our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:18.669774Z",
     "iopub.status.busy": "2022-10-05T21:40:18.669458Z",
     "iopub.status.idle": "2022-10-05T21:40:18.675767Z",
     "shell.execute_reply": "2022-10-05T21:40:18.674733Z",
     "shell.execute_reply.started": "2022-10-05T21:40:18.669749Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    fig, axis = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "    for i, img in enumerate(images):\n",
    "        ax = axis[i]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:25.264993Z",
     "iopub.status.busy": "2022-10-05T21:40:25.264668Z",
     "iopub.status.idle": "2022-10-05T21:40:25.723657Z",
     "shell.execute_reply": "2022-10-05T21:40:25.721851Z",
     "shell.execute_reply.started": "2022-10-05T21:40:25.264967Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_images(t.images[11:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Images to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:40:38.023367Z",
     "iopub.status.busy": "2022-10-05T21:40:38.023017Z",
     "iopub.status.idle": "2022-10-05T21:40:38.029999Z",
     "shell.execute_reply": "2022-10-05T21:40:38.028891Z",
     "shell.execute_reply.started": "2022-10-05T21:40:38.023342Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_np_to_tensor(images_np, to_tensor):\n",
    "    images_t = torch.zeros(images_np.shape[0], 1, images_np.shape[1], images_np.shape[2])\n",
    "    for i in range(images_np.shape[0]):\n",
    "        images_t[i] = to_tensor(images_np[i])\n",
    "    return images_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:41:04.395051Z",
     "iopub.status.busy": "2022-10-05T21:41:04.394718Z",
     "iopub.status.idle": "2022-10-05T21:41:04.433946Z",
     "shell.execute_reply": "2022-10-05T21:41:04.432958Z",
     "shell.execute_reply.started": "2022-10-05T21:41:04.395026Z"
    }
   },
   "outputs": [],
   "source": [
    "t.images_t = image_np_to_tensor(t.images, t.to_tensor).to(t.device)\n",
    "t.images_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Model\n",
    "\n",
    "Pytorch doesn't provide a \"reshape\" layer that we will need for our model. They didn't provide \"Flatten\" for a while either, but then added it. The hope is they will add Reshape at some point as well.\n",
    "\n",
    "For now, we'll just implement. All NN layers inherit from nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:42:32.315305Z",
     "iopub.status.busy": "2022-10-05T21:42:32.314897Z",
     "iopub.status.idle": "2022-10-05T21:42:32.321452Z",
     "shell.execute_reply": "2022-10-05T21:42:32.319959Z",
     "shell.execute_reply.started": "2022-10-05T21:42:32.315275Z"
    }
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:54:53.458495Z",
     "iopub.status.busy": "2022-10-05T21:54:53.458153Z",
     "iopub.status.idle": "2022-10-05T21:54:53.479553Z",
     "shell.execute_reply": "2022-10-05T21:54:53.478787Z",
     "shell.execute_reply.started": "2022-10-05T21:54:53.458471Z"
    }
   },
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._total_epochs = 0\n",
    "        self._training_time_s = 0\n",
    "        self._timer = None\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "        #     # C2: 1 ch, 64 x 64 \n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0),\n",
    "        #     # C2: 1 ch, 32 x 32 \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0),\n",
    "        #     # C3: 16 x 16\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0),\n",
    "        #     # C3: 8 x 8\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0),\n",
    "        #     # C4: 4 x 4            \n",
    "            nn.Flatten(),    \n",
    "            nn.Linear(64 * 4 * 4, 2),\n",
    "        ).to(t.device)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 64 * 4 * 4),\n",
    "            Reshape(-1, 64, 4, 4),\n",
    "            # 4 x 4\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # 8 x 8 \n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # 16 x 16\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # # 32 x 32\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2),  \n",
    "            # 64 x 64\n",
    "            nn.Sigmoid(),\n",
    "        ).to(t.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def start_training(self): \n",
    "        if not self._timer:\n",
    "            self._timer = timeit.default_timer()\n",
    "    \n",
    "    def end_training(self):\n",
    "        self._training_time_s += timeit.default_timer() - self._timer\n",
    "        self._timer = None\n",
    "        \n",
    "    def add_epochs(self, epochs):\n",
    "        self._total_epochs += epochs\n",
    "        \n",
    "    def total_epochs(self):\n",
    "        return self._total_epochs\n",
    "    \n",
    "    def training_timedelta(self) -> timedelta:\n",
    "        return timedelta(seconds=self._training_time_s)\n",
    "\n",
    "t.model = AE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:54:53.853674Z",
     "iopub.status.busy": "2022-10-05T21:54:53.853016Z",
     "iopub.status.idle": "2022-10-05T21:54:53.861098Z",
     "shell.execute_reply": "2022-10-05T21:54:53.859778Z",
     "shell.execute_reply.started": "2022-10-05T21:54:53.853619Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Trainable parameters:', sum(p.numel() for p in t.model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot input and output images before training\n",
    "\n",
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T21:54:54.587798Z",
     "iopub.status.busy": "2022-10-05T21:54:54.587453Z",
     "iopub.status.idle": "2022-10-05T21:54:54.824055Z",
     "shell.execute_reply": "2022-10-05T21:54:54.823422Z",
     "shell.execute_reply.started": "2022-10-05T21:54:54.587773Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 100\n",
    "plot_images(t.images[i:i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would output, that is, decoded images will look like now, before we did no training of the network?\n",
    "\n",
    "Let's pass images through the network, that is:\n",
    "\n",
    "```\n",
    "Input Image -> Encoder -> (0.1, -2.3) -> Decoder -> Output Image\n",
    "```\n",
    "\n",
    "Execute the model, both encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:00:37.444577Z",
     "iopub.status.busy": "2022-10-05T22:00:37.444207Z",
     "iopub.status.idle": "2022-10-05T22:00:37.465161Z",
     "shell.execute_reply": "2022-10-05T22:00:37.464431Z",
     "shell.execute_reply.started": "2022-10-05T22:00:37.444551Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = t.model(t.images_t[i: i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:00:37.896290Z",
     "iopub.status.busy": "2022-10-05T22:00:37.895954Z",
     "iopub.status.idle": "2022-10-05T22:00:37.905587Z",
     "shell.execute_reply": "2022-10-05T22:00:37.903975Z",
     "shell.execute_reply.started": "2022-10-05T22:00:37.896264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move images to CPU\n",
    "imgs = imgs.cpu()\n",
    "\n",
    "# Disconnect from training data structures, \n",
    "# or Pytorch will complain during the conversion to numpy\n",
    "imgs = imgs.detach()\n",
    "\n",
    "# Conver to Numpy\n",
    "imgs = imgs.numpy()\n",
    "\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get rid of an extra dimension, \"1\". Pytorch requires, but our drawing functions won't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:00:39.201712Z",
     "iopub.status.busy": "2022-10-05T22:00:39.201301Z",
     "iopub.status.idle": "2022-10-05T22:00:39.212453Z",
     "shell.execute_reply": "2022-10-05T22:00:39.210569Z",
     "shell.execute_reply.started": "2022-10-05T22:00:39.201687Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = np.squeeze(imgs, axis=1)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect output images to look like now? To test your intiuition, try to imagine the result, then run the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:01:35.092988Z",
     "iopub.status.busy": "2022-10-05T22:01:35.092631Z",
     "iopub.status.idle": "2022-10-05T22:01:35.353879Z",
     "shell.execute_reply": "2022-10-05T22:01:35.352315Z",
     "shell.execute_reply.started": "2022-10-05T22:01:35.092961Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_images(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:02:25.704309Z",
     "iopub.status.busy": "2022-10-05T22:02:25.703972Z",
     "iopub.status.idle": "2022-10-05T22:02:25.714067Z",
     "shell.execute_reply": "2022-10-05T22:02:25.713134Z",
     "shell.execute_reply.started": "2022-10-05T22:02:25.704284Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, n_epochs, train_images, opt, criterion, report_each_nth_epoch):\n",
    "    batch_size = 16\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if model.total_epochs() >= n_epochs:\n",
    "            break\n",
    "        model.start_training()\n",
    "        batch_count = int(train_images.shape[0] / batch_size) + 1\n",
    "        for i in range(0, batch_count):\n",
    "            start_i = i * batch_size\n",
    "            image_batch = train_images[start_i : start_i + batch_size]\n",
    "            if image_batch.shape[0] > 0:\n",
    "                output = model(image_batch)\n",
    "                loss = criterion(output, image_batch)\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        model.add_epochs(1)\n",
    "        if epoch % report_each_nth_epoch == 0:\n",
    "            model.end_training()\n",
    "            avg_error = loss.item()\n",
    "            print(f\" Epoch {epoch}\",\n",
    "                  f\"\\n Train loss: {avg_error}\",\n",
    "                  f\"\\n Total epochs: {model._total_epochs}\",\n",
    "                  f\"\\n Total training time: {model.training_timedelta()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Algorithm and the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:03:07.081605Z",
     "iopub.status.busy": "2022-10-05T22:03:07.081273Z",
     "iopub.status.idle": "2022-10-05T22:03:07.087606Z",
     "shell.execute_reply": "2022-10-05T22:03:07.086427Z",
     "shell.execute_reply.started": "2022-10-05T22:03:07.081581Z"
    }
   },
   "outputs": [],
   "source": [
    "t.mse_loss_base = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "def mse_loss(pred, y_true):\n",
    "    pixel_loss = t.mse_loss_base(pred, y_true)\n",
    "    batch_size = y_true.shape[0]\n",
    "    pixel_loss_sum = pixel_loss.view(batch_size, -1).sum(axis=1) # sum over pixels\n",
    "    loss = pixel_loss_sum.mean() # Mean over the batch\n",
    "    return loss\n",
    "\n",
    "t.criterion = mse_loss\n",
    "t.opt = torch.optim.Adam(t.model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-05T22:03:08.722923Z",
     "iopub.status.busy": "2022-10-05T22:03:08.721687Z"
    }
   },
   "outputs": [],
   "source": [
    "train(t.model, 2300, t.images_t, t.opt, t.criterion, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See Results\n",
    "\n",
    "## Plot original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "plot_images(t.images[i:i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot output images\n",
    "\n",
    "Using the same method as above, only collected into a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass source images through the network, i.e. x_hat = Decoder(Encoder(x))\n",
    "imgs = t.model(t.images_t[i: i+5])\n",
    "\n",
    "# Convert to numpy and plot\n",
    "plot_images(np.squeeze(imgs.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.model.encoder(t.images_t[0: 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model\n",
    "\n",
    "Just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(t.model, 'cylinder_autoencoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Autoencoder\n",
    "\n",
    "Pass all images through the Encoder, and plot the points in teh 2-D latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, load the model from the file if you pre-trained it prevously. Otherwise, use current results.\n",
    "\n",
    "## 1. Load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file \n",
    "\n",
    "\n",
    "# a = Object()\n",
    "# a.model = torch.load('../input/model123/model.pkl', map_location=t.device)\n",
    "# _ = a.model.eval()\n",
    "# _ = a.model.encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Or, Use Current Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pass All Images Through the Encoder Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass through model\n",
    "a.output = a.model.encoder(t.images_t)\n",
    "\n",
    "# Convert to numpy\n",
    "a.emb = a.output.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What would be the output of the Encoder?**\n",
    "\n",
    "**Q2. What is the shape of the output?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.emb[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot All Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.grid()\n",
    "plt.scatter(a.emb[:,0], a.emb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dream_cylinder(x, y):\n",
    "    plt.imshow(\n",
    "        a.model.decoder(torch.tensor([x*1.0, y]).to(t.device)).detach().cpu().numpy()[0][0],\n",
    "        cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_cylinder(0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_space(\n",
    "    model: AE,\n",
    "    x_range: Tuple[int], \n",
    "    y_range: Tuple[int], \n",
    "    wh: Tuple[int], \n",
    "    n: int):\n",
    "    w = wh[0]\n",
    "    big_img = np.zeros((w * n, w * n))\n",
    "    xs = np.linspace(x_range[0], x_range[1], n)\n",
    "    ys = np.linspace(y_range[0], y_range[1], n)\n",
    "    for i, y in enumerate(ys):\n",
    "        for j, x in enumerate(xs):\n",
    "            z = torch.Tensor([[x, y]]).to(t.device)\n",
    "            input_hat = model.decoder(z) \\\n",
    "                .reshape(w, w) \\\n",
    "                .to('cpu') \\\n",
    "                .detach() \\\n",
    "                .numpy()\n",
    "            big_img[(n - 1 - i) * w : (n - 1 - i + 1) * w,\n",
    "                j * w : (j + 1) * w] = input_hat\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(big_img, extent=[*x_range, *y_range], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.x_range = (a.emb[:,0].min(), a.emb[:,0].max())\n",
    "# t.y_range = (a.emb[:,1].min(), a.emb[:,1].max())\n",
    "\n",
    "plot_embedding_space(t.model, \n",
    "                     x_range=(-7.5, 10), \n",
    "                     y_range=(-2, 10), \n",
    "                     wh=(64, 64),\n",
    "                     n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
