{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efee901",
   "metadata": {
    "papermill": {
     "duration": 0.067935,
     "end_time": "2022-12-11T01:34:59.752975",
     "exception": false,
     "start_time": "2022-12-11T01:34:59.685040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78af41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:34:59.770254Z",
     "iopub.status.busy": "2022-12-11T01:34:59.769234Z",
     "iopub.status.idle": "2022-12-11T01:34:59.784052Z",
     "shell.execute_reply": "2022-12-11T01:34:59.782879Z"
    },
    "papermill": {
     "duration": 0.025456,
     "end_time": "2022-12-11T01:34:59.785686",
     "exception": false,
     "start_time": "2022-12-11T01:34:59.760230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "# We'll store all our variables here.\n",
    "t = Object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abdf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:34:59.806661Z",
     "iopub.status.busy": "2022-12-11T01:34:59.805909Z",
     "iopub.status.idle": "2022-12-11T01:34:59.831334Z",
     "shell.execute_reply": "2022-12-11T01:34:59.830219Z"
    },
    "papermill": {
     "duration": 0.037967,
     "end_time": "2022-12-11T01:34:59.833437",
     "exception": false,
     "start_time": "2022-12-11T01:34:59.795470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd4ce2",
   "metadata": {
    "papermill": {
     "duration": 0.009199,
     "end_time": "2022-12-11T01:34:59.856959",
     "exception": false,
     "start_time": "2022-12-11T01:34:59.847760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317e793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:34:59.873882Z",
     "iopub.status.busy": "2022-12-11T01:34:59.873056Z",
     "iopub.status.idle": "2022-12-11T01:35:00.481632Z",
     "shell.execute_reply": "2022-12-11T01:35:00.480833Z"
    },
    "papermill": {
     "duration": 0.618715,
     "end_time": "2022-12-11T01:35:00.483330",
     "exception": false,
     "start_time": "2022-12-11T01:34:59.864615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdaa7a7",
   "metadata": {
    "papermill": {
     "duration": 0.00721,
     "end_time": "2022-12-11T01:35:00.497673",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.490463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Numpy and graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b1eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:00.514076Z",
     "iopub.status.busy": "2022-12-11T01:35:00.513125Z",
     "iopub.status.idle": "2022-12-11T01:35:00.910377Z",
     "shell.execute_reply": "2022-12-11T01:35:00.909609Z"
    },
    "papermill": {
     "duration": 0.407444,
     "end_time": "2022-12-11T01:35:00.912117",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.504673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timeit\n",
    "import datetime\n",
    "import sys\n",
    "import random\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65885f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T19:39:25.750133Z",
     "iopub.status.busy": "2022-10-07T19:39:25.749711Z",
     "iopub.status.idle": "2022-10-07T19:39:25.757736Z",
     "shell.execute_reply": "2022-10-07T19:39:25.755928Z",
     "shell.execute_reply.started": "2022-10-07T19:39:25.750098Z"
    },
    "papermill": {
     "duration": 0.006837,
     "end_time": "2022-12-11T01:35:00.926224",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.919387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will keep variables inside an object to avoid pulluting the global namespace and prevent various bugs. The defition below allows adding attributes at runtime:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933235c",
   "metadata": {
    "papermill": {
     "duration": 0.006861,
     "end_time": "2022-12-11T01:35:00.940052",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.933191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings\n",
    "\n",
    "You need to add the CelebA dataset to your Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c286c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:00.955768Z",
     "iopub.status.busy": "2022-12-11T01:35:00.954967Z",
     "iopub.status.idle": "2022-12-11T01:35:00.961065Z",
     "shell.execute_reply": "2022-12-11T01:35:00.959943Z"
    },
    "papermill": {
     "duration": 0.015338,
     "end_time": "2022-12-11T01:35:00.962191",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.946853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.image_root = \"../../../../data/vae/img_align_celeba/\"\n",
    "t.image_folder = f\"{t.image_root}/img_align_celeba\"\n",
    "\n",
    "# t.image_root = \"../input/celeba-dataset/\"\n",
    "# t.image_folder = f\"{t.image_root}/img_align_celeba/img_align_celeba\"\n",
    "\n",
    "t.output_folder = \"../working\"\n",
    "t.crop_size = 178"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700f13f",
   "metadata": {
    "papermill": {
     "duration": 0.007015,
     "end_time": "2022-12-11T01:35:00.978371",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.971356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For reproducibility, we will set a fixed seed for all randomized functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c48689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:00.993381Z",
     "iopub.status.busy": "2022-12-11T01:35:00.992940Z",
     "iopub.status.idle": "2022-12-11T01:35:01.000518Z",
     "shell.execute_reply": "2022-12-11T01:35:00.999922Z"
    },
    "papermill": {
     "duration": 0.018287,
     "end_time": "2022-12-11T01:35:01.003240",
     "exception": false,
     "start_time": "2022-12-11T01:35:00.984953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.seed = 1\n",
    "torch.manual_seed(t.seed)\n",
    "torch.cuda.manual_seed(t.seed)\n",
    "torch.cuda.manual_seed_all(t.seed)\n",
    "np.random.seed(t.seed)\n",
    "# For complete reproducibility\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec9f4a",
   "metadata": {
    "papermill": {
     "duration": 0.010507,
     "end_time": "2022-12-11T01:35:01.033179",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.022672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set Device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a17ab",
   "metadata": {
    "papermill": {
     "duration": 0.006897,
     "end_time": "2022-12-11T01:35:01.047349",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.040452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can run our code on GPU or CPU, if GPU is not present. Training will be very slow on CPU. However, we can pre-train our model on GPU, save, and then experiment with it on CPU. That'll be reasonably fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca334efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:01.062125Z",
     "iopub.status.busy": "2022-12-11T01:35:01.061803Z",
     "iopub.status.idle": "2022-12-11T01:35:01.091488Z",
     "shell.execute_reply": "2022-12-11T01:35:01.090800Z"
    },
    "papermill": {
     "duration": 0.039147,
     "end_time": "2022-12-11T01:35:01.093314",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.054167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "t.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff7a34",
   "metadata": {
    "papermill": {
     "duration": 0.009258,
     "end_time": "2022-12-11T01:35:01.117892",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.108634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d0483",
   "metadata": {
    "papermill": {
     "duration": 0.006715,
     "end_time": "2022-12-11T01:35:01.132013",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.125298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will no longer load all images into memory because it's not efficient, and the dataset is too large. We will use the Pytroch's Data Loader to load images efficiently.\n",
    "\n",
    "The data loader concept uses two objects:\n",
    "\n",
    "1. Data Set - represents the actual data, or, in our case, images.\n",
    "2. Data Loader - specializes in loading, converting and passing the data to the model.\n",
    "\n",
    "Let's start by defining the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ef40b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:01.147608Z",
     "iopub.status.busy": "2022-12-11T01:35:01.146971Z",
     "iopub.status.idle": "2022-12-11T01:35:01.154394Z",
     "shell.execute_reply": "2022-12-11T01:35:01.153286Z"
    },
    "papermill": {
     "duration": 0.017161,
     "end_time": "2022-12-11T01:35:01.155962",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.138801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "def plot_images(images):\n",
    "    fig, axis = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "    for i, im in enumerate(images):\n",
    "        ax = axis[i]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046efbc",
   "metadata": {
    "papermill": {
     "duration": 0.007867,
     "end_time": "2022-12-11T01:35:01.173326",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.165459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Image Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846258e",
   "metadata": {
    "papermill": {
     "duration": 0.006669,
     "end_time": "2022-12-11T01:35:01.186996",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.180327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Move images into subfolders for classes \"with smile\", \"no smile\" as ImageFolder expects. We will use these classes to transform images from \"no smiles\", to \"smiles\".\n",
    "\n",
    "First, we read the 'smile' attribute from a CSV file that maps images to smile setting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb1a06",
   "metadata": {
    "papermill": {
     "duration": 0.006844,
     "end_time": "2022-12-11T01:35:01.200527",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.193683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895ee79",
   "metadata": {
    "papermill": {
     "duration": 0.006663,
     "end_time": "2022-12-11T01:35:01.213894",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.207231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will create a custom dataset object to return files in the order we want:\n",
    "\n",
    "1. Return training subset\n",
    "1. Use validation subset for validation\n",
    "1. All faces will be labeled either smile or no smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973456c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:01.229579Z",
     "iopub.status.busy": "2022-12-11T01:35:01.228932Z",
     "iopub.status.idle": "2022-12-11T01:35:01.249161Z",
     "shell.execute_reply": "2022-12-11T01:35:01.248019Z"
    },
    "papermill": {
     "duration": 0.030149,
     "end_time": "2022-12-11T01:35:01.251013",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.220864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class ImageTensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_folder, image_folder, transform, is_train):\n",
    "        self.folder = image_folder\n",
    "        self.int_to_smile = {-1: \"no_smile\", 1: \"smile\"}\n",
    "        self.smile_to_int = {\n",
    "            self.int_to_smile[1]: 1,\n",
    "            self.int_to_smile[-1]: -1\n",
    "        }\n",
    "        self.image_to_smile = {}\n",
    "        self.smile_to_image = {\"no_smile\":[], \"smile\":[]}\n",
    "        self.dataset_split = {\"train\": [], \"valid\":[], \"test\":[]}\n",
    "        self.dataset_split_translation = {0: \"train\", 1: \"valid\", 2: \"test\"}\n",
    "        self.load_metadata(csv_folder)\n",
    "        self.set_type = \"train\" if is_train else \"valid\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def load_metadata(self, csv_folder):\n",
    "        for r in csv.DictReader(open(f\"{csv_folder}/list_attr_celeba.csv\")):\n",
    "            self.image_to_smile[r['image_id']] = int(r['Smiling'])\n",
    "            self.smile_to_image[self.int_to_smile[int(r['Smiling'])]].append(r['image_id'])\n",
    "        for r in csv.DictReader(open(f\"{csv_folder}/list_eval_partition.csv\")):\n",
    "            partition = int(r[\"partition\"])\n",
    "            translated_partition = self.dataset_split_translation[partition]\n",
    "            self.dataset_split[translated_partition].append(r['image_id'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_split[self.set_type])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        files = self.dataset_split[self.set_type]\n",
    "        file_id = files[index]\n",
    "        file_path = self.folder + \"/\" + file_id\n",
    "        im = self.transform(Image.open(file_path))\n",
    "        return im, self.image_to_smile[file_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c7224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:01.278944Z",
     "iopub.status.busy": "2022-12-11T01:35:01.278294Z",
     "iopub.status.idle": "2022-12-11T01:35:01.283308Z",
     "shell.execute_reply": "2022-12-11T01:35:01.282660Z"
    },
    "papermill": {
     "duration": 0.020168,
     "end_time": "2022-12-11T01:35:01.286590",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.266422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.CenterCrop(t.crop_size), \n",
    "        transforms.Resize(128),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772031e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:01.318153Z",
     "iopub.status.busy": "2022-12-11T01:35:01.317756Z",
     "iopub.status.idle": "2022-12-11T01:35:02.420340Z",
     "shell.execute_reply": "2022-12-11T01:35:02.419344Z"
    },
    "papermill": {
     "duration": 1.117732,
     "end_time": "2022-12-11T01:35:02.423601",
     "exception": false,
     "start_time": "2022-12-11T01:35:01.305869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.train_dataset = ImageTensorDataset(\n",
    "    t.image_root, \n",
    "    t.image_folder, \n",
    "    t.train_transform, \n",
    "    is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d0636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:02.443748Z",
     "iopub.status.busy": "2022-12-11T01:35:02.442797Z",
     "iopub.status.idle": "2022-12-11T01:35:03.519144Z",
     "shell.execute_reply": "2022-12-11T01:35:03.518221Z"
    },
    "papermill": {
     "duration": 1.08869,
     "end_time": "2022-12-11T01:35:03.522463",
     "exception": false,
     "start_time": "2022-12-11T01:35:02.433773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.valid_dataset = ImageTensorDataset(\n",
    "    t.image_root, \n",
    "    t.image_folder, \n",
    "    t.train_transform, \n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6b052",
   "metadata": {
    "papermill": {
     "duration": 0.011956,
     "end_time": "2022-12-11T01:35:03.556277",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.544321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Init Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b4772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:03.572837Z",
     "iopub.status.busy": "2022-12-11T01:35:03.572310Z",
     "iopub.status.idle": "2022-12-11T01:35:03.577479Z",
     "shell.execute_reply": "2022-12-11T01:35:03.576439Z"
    },
    "papermill": {
     "duration": 0.014718,
     "end_time": "2022-12-11T01:35:03.578801",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.564083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.train_loader = torch.utils.data.DataLoader(\n",
    "    t.train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571783c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:03.594862Z",
     "iopub.status.busy": "2022-12-11T01:35:03.594405Z",
     "iopub.status.idle": "2022-12-11T01:35:03.599947Z",
     "shell.execute_reply": "2022-12-11T01:35:03.599033Z"
    },
    "papermill": {
     "duration": 0.015106,
     "end_time": "2022-12-11T01:35:03.601283",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.586177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.valid_loader = torch.utils.data.DataLoader(\n",
    "    t.valid_dataset,\n",
    "    batch_size=512,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc16251",
   "metadata": {
    "papermill": {
     "duration": 0.007154,
     "end_time": "2022-12-11T01:35:03.615455",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.608301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Test loader is the same dataset, but 1024 samples, sampled from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a06fb0",
   "metadata": {
    "papermill": {
     "duration": 0.006749,
     "end_time": "2022-12-11T01:35:03.629153",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.622404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read a small sample of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b66753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:03.644680Z",
     "iopub.status.busy": "2022-12-11T01:35:03.644225Z",
     "iopub.status.idle": "2022-12-11T01:35:03.651869Z",
     "shell.execute_reply": "2022-12-11T01:35:03.650951Z"
    },
    "papermill": {
     "duration": 0.017193,
     "end_time": "2022-12-11T01:35:03.653213",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.636020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_images(train_loader, count):\n",
    "    images = None\n",
    "    remain = count\n",
    "    for data in train_loader:\n",
    "        batch_images, labels = data\n",
    "        if images is None:\n",
    "            images = batch_images[0:remain]\n",
    "        else:\n",
    "            images = torch.cat((images, batch_images), 0)\n",
    "        remain -= min(remain, batch_images.size(0))\n",
    "        if remain <= 0:\n",
    "            break\n",
    "    return images.to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a8255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:03.671124Z",
     "iopub.status.busy": "2022-12-11T01:35:03.670418Z",
     "iopub.status.idle": "2022-12-11T01:35:05.688613Z",
     "shell.execute_reply": "2022-12-11T01:35:05.687576Z"
    },
    "papermill": {
     "duration": 2.030792,
     "end_time": "2022-12-11T01:35:05.691636",
     "exception": false,
     "start_time": "2022-12-11T01:35:03.660844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.sample_images = read_images(t.train_loader, 10)\n",
    "t.sample_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426dc0b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T05:44:45.049243Z",
     "iopub.status.busy": "2022-10-09T05:44:45.048354Z",
     "iopub.status.idle": "2022-10-09T05:44:45.055985Z",
     "shell.execute_reply": "2022-10-09T05:44:45.054277Z",
     "shell.execute_reply.started": "2022-10-09T05:44:45.049204Z"
    },
    "papermill": {
     "duration": 0.010692,
     "end_time": "2022-12-11T01:35:05.722042",
     "exception": false,
     "start_time": "2022-12-11T01:35:05.711350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The function to display our images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b5940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:05.757217Z",
     "iopub.status.busy": "2022-12-11T01:35:05.756708Z",
     "iopub.status.idle": "2022-12-11T01:35:05.763436Z",
     "shell.execute_reply": "2022-12-11T01:35:05.762277Z"
    },
    "papermill": {
     "duration": 0.023978,
     "end_time": "2022-12-11T01:35:05.764937",
     "exception": false,
     "start_time": "2022-12-11T01:35:05.740959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_images_tensor(images_t):\n",
    "    images = images_t.cpu().detach().permute(0, 2, 3, 1).numpy()\n",
    "    fig, axis = plt.subplots(1, max(images.shape[0], 2), figsize=(20, 5))\n",
    "    for i, im in enumerate(images):\n",
    "        axis[i].axis('off')\n",
    "        axis[i].imshow(im)\n",
    "        \n",
    "def plot_images(images):\n",
    "    fig, axis = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "    for i, im in enumerate(images):\n",
    "        ax = axis[i]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ab258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:05.783060Z",
     "iopub.status.busy": "2022-12-11T01:35:05.782181Z",
     "iopub.status.idle": "2022-12-11T01:35:06.009761Z",
     "shell.execute_reply": "2022-12-11T01:35:06.008775Z"
    },
    "papermill": {
     "duration": 0.250286,
     "end_time": "2022-12-11T01:35:06.023599",
     "exception": false,
     "start_time": "2022-12-11T01:35:05.773313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images_tensor(t.sample_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb28fe1",
   "metadata": {
    "papermill": {
     "duration": 0.00972,
     "end_time": "2022-12-11T01:35:06.049942",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.040222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset maps folder names to class IDs. In our case, `0` will mean no smile, while `1` smile. This is very reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b6d63",
   "metadata": {
    "papermill": {
     "duration": 0.008721,
     "end_time": "2022-12-11T01:35:06.067601",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.058880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Design Model\n",
    "\n",
    "Pytorch doesn't provide a \"reshape\" layer that we will need for our model. They didn't provide \"Flatten\" for a while either, but then added it. The hope is they will add Reshape at some point as well.\n",
    "\n",
    "For now, we'll just implement. All NN layers inherit from nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220d1be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.086772Z",
     "iopub.status.busy": "2022-12-11T01:35:06.086416Z",
     "iopub.status.idle": "2022-12-11T01:35:06.090788Z",
     "shell.execute_reply": "2022-12-11T01:35:06.090303Z"
    },
    "papermill": {
     "duration": 0.015553,
     "end_time": "2022-12-11T01:35:06.091910",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.076357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfc4cb",
   "metadata": {
    "papermill": {
     "duration": 0.009419,
     "end_time": "2022-12-11T01:35:06.110585",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.101166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model\n",
    "\n",
    "We now need to do extra steps during encoding, e.g. sampling from the normal distribution. So, we'll define our standard layers as `_encoder_main` and will have a function `encode` that will call layers, and do additional work.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85828c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.130590Z",
     "iopub.status.busy": "2022-12-11T01:35:06.130159Z",
     "iopub.status.idle": "2022-12-11T01:35:06.181033Z",
     "shell.execute_reply": "2022-12-11T01:35:06.180266Z"
    },
    "papermill": {
     "duration": 0.063559,
     "end_time": "2022-12-11T01:35:06.183055",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.119496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytz \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._total_epochs = 0\n",
    "        self._training_time_s = 0\n",
    "        self._timer = None\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        if device.type == 'cuda':\n",
    "            self.N.loc = self.N.loc.cuda()\n",
    "            self.N.scale = self.N.scale.cuda()\n",
    "        \n",
    "        self.model_file_name = f\"faces_vae_\" \\\n",
    "            + datetime.datetime.now().astimezone(pytz.timezone('US/Pacific')).strftime(\"%Y-%m-%d_%H-%M\") \\\n",
    "            + \".pkl\"\n",
    "\n",
    "        self.z_mean = torch.nn.Linear(64 * 8 * 8, 200)\n",
    "        self.log_var = torch.nn.Linear(64 * 8 * 8, 200)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 128 x 128\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            # 64 x 64\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            # 32 x 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            # 16 x 16\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "        )\n",
    "                \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(200, 64 * 8 * 8),\n",
    "            Reshape(-1, 64, 8, 8),\n",
    "            \n",
    "            # 8 x 8 \n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 16 x 16\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # 32 x 32\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # 64 x 64\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),  \n",
    "#             nn.BatchNorm2d(32),\n",
    "            nn.Sigmoid(),\n",
    "            \n",
    "            # 128 x 128\n",
    "        )\n",
    "        \n",
    "        self.to(device)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, log_var = self.z_mean(x), self.log_var(x)\n",
    "        std_dev = torch.exp(0.5 * log_var)\n",
    "        eps = self.N.sample(z_mean.shape)\n",
    "        encoded = z_mean + eps * std_dev\n",
    "        return encoded, z_mean, log_var\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded, z_mean, log_var = self.encode(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, z_mean, log_var\n",
    "    \n",
    "    def start_training(self):\n",
    "        if self._timer is None:\n",
    "            self._timer = timeit.default_timer()\n",
    "\n",
    "    def end_training(self):\n",
    "        if self._timer:\n",
    "            self._training_time_s += timeit.default_timer() - self._timer\n",
    "            self._timer = None\n",
    "\n",
    "    def add_epochs(self, epochs):\n",
    "        self._total_epochs += epochs\n",
    "        \n",
    "    def training_timedelta(self):\n",
    "        return datetime.timedelta(seconds=self._training_time_s)\n",
    "    \n",
    "t.model = VAE(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13babebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.211896Z",
     "iopub.status.busy": "2022-12-11T01:35:06.211738Z",
     "iopub.status.idle": "2022-12-11T01:35:06.215945Z",
     "shell.execute_reply": "2022-12-11T01:35:06.215436Z"
    },
    "papermill": {
     "duration": 0.01638,
     "end_time": "2022-12-11T01:35:06.217079",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.200699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Parameters: ', sum(p.numel() for p in t.model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5cf11",
   "metadata": {
    "papermill": {
     "duration": 0.009086,
     "end_time": "2022-12-11T01:35:06.235236",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.226150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b053bd7",
   "metadata": {
    "papermill": {
     "duration": 0.008901,
     "end_time": "2022-12-11T01:35:06.253321",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.244420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56609d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.273311Z",
     "iopub.status.busy": "2022-12-11T01:35:06.272602Z",
     "iopub.status.idle": "2022-12-11T01:35:06.279024Z",
     "shell.execute_reply": "2022-12-11T01:35:06.278343Z"
    },
    "papermill": {
     "duration": 0.017966,
     "end_time": "2022-12-11T01:35:06.280279",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.262313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.mse_loss_base = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "def mse_loss(pred, y_true):\n",
    "    pixel_loss = t.mse_loss_base(pred, y_true)\n",
    "    batch_size = y_true.shape[0]\n",
    "    pixel_loss_sum = pixel_loss.view(batch_size, -1).sum(axis=1) # sum over pixels\n",
    "    loss = pixel_loss_sum.mean() # mean over batch\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40896705",
   "metadata": {
    "papermill": {
     "duration": 0.009317,
     "end_time": "2022-12-11T01:35:06.300297",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.290980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978da037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.319941Z",
     "iopub.status.busy": "2022-12-11T01:35:06.319632Z",
     "iopub.status.idle": "2022-12-11T01:35:06.325642Z",
     "shell.execute_reply": "2022-12-11T01:35:06.324956Z"
    },
    "papermill": {
     "duration": 0.017475,
     "end_time": "2022-12-11T01:35:06.326877",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.309402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kl_div(z_mean, log_var):\n",
    "    mu = z_mean\n",
    "    var = torch.exp(log_var)\n",
    "    kl_loss_sum = -0.5 * (1 + log_var - mu**2 - var).sum(axis=1) # sum over dimensions\n",
    "    kl_loss = kl_loss_sum.mean() # mean over batch\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1905c4",
   "metadata": {
    "papermill": {
     "duration": 0.008973,
     "end_time": "2022-12-11T01:35:06.345582",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.336609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## VAE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d3369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.365888Z",
     "iopub.status.busy": "2022-12-11T01:35:06.365231Z",
     "iopub.status.idle": "2022-12-11T01:35:06.370617Z",
     "shell.execute_reply": "2022-12-11T01:35:06.369944Z"
    },
    "papermill": {
     "duration": 0.016955,
     "end_time": "2022-12-11T01:35:06.371819",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.354864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vae_loss(pred, y_true, kl_factor, z_mean, log_var):\n",
    "    r_loss = mse_loss(pred, y_true)\n",
    "    kl_loss = kl_div(z_mean, log_var)\n",
    "    return r_loss + kl_factor * kl_loss, r_loss, kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a1deb",
   "metadata": {
    "papermill": {
     "duration": 0.009624,
     "end_time": "2022-12-11T01:35:06.393074",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.383450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Analyze Images Before Training\n",
    "\n",
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e3e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.413107Z",
     "iopub.status.busy": "2022-12-11T01:35:06.412342Z",
     "iopub.status.idle": "2022-12-11T01:35:06.625116Z",
     "shell.execute_reply": "2022-12-11T01:35:06.624481Z"
    },
    "papermill": {
     "duration": 0.231922,
     "end_time": "2022-12-11T01:35:06.634091",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.402169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.i = 1\n",
    "plot_images_tensor(t.sample_images[t.i:t.i+10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee0a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:01:44.651549Z",
     "iopub.status.busy": "2022-10-07T20:01:44.651079Z",
     "iopub.status.idle": "2022-10-07T20:01:44.661648Z",
     "shell.execute_reply": "2022-10-07T20:01:44.659885Z",
     "shell.execute_reply.started": "2022-10-07T20:01:44.651496Z"
    },
    "papermill": {
     "duration": 0.011509,
     "end_time": "2022-12-11T01:35:06.662977",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.651468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What would output, that is, decoded images will look like now, before we did no training of the network? Let's pass images through the network, that is, execute the sequence:\n",
    "\n",
    "    Input Image -> Encoder -> (0.1, -2.3) -> Decoder -> Output Image\n",
    "    \n",
    "Let's run the end-to-end model, both encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08865334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:06.687519Z",
     "iopub.status.busy": "2022-12-11T01:35:06.686562Z",
     "iopub.status.idle": "2022-12-11T01:35:07.226982Z",
     "shell.execute_reply": "2022-12-11T01:35:07.225921Z"
    },
    "papermill": {
     "duration": 0.55632,
     "end_time": "2022-12-11T01:35:07.230313",
     "exception": false,
     "start_time": "2022-12-11T01:35:06.673993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.sample_output = t.model(t.sample_images[t.i : t.i+10])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca0242",
   "metadata": {
    "papermill": {
     "duration": 0.01349,
     "end_time": "2022-12-11T01:35:07.271970",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.258480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What is the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f025c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:07.296655Z",
     "iopub.status.busy": "2022-12-11T01:35:07.295718Z",
     "iopub.status.idle": "2022-12-11T01:35:07.303110Z",
     "shell.execute_reply": "2022-12-11T01:35:07.302210Z"
    },
    "papermill": {
     "duration": 0.021562,
     "end_time": "2022-12-11T01:35:07.304677",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.283115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.sample_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c6a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:07:05.555354Z",
     "iopub.status.busy": "2022-10-07T20:07:05.55492Z",
     "iopub.status.idle": "2022-10-07T20:07:05.563274Z",
     "shell.execute_reply": "2022-10-07T20:07:05.561684Z",
     "shell.execute_reply.started": "2022-10-07T20:07:05.555319Z"
    },
    "papermill": {
     "duration": 0.011408,
     "end_time": "2022-12-11T01:35:07.329878",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.318470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Display output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160087da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:07.354149Z",
     "iopub.status.busy": "2022-12-11T01:35:07.353236Z",
     "iopub.status.idle": "2022-12-11T01:35:07.652919Z",
     "shell.execute_reply": "2022-12-11T01:35:07.652301Z"
    },
    "papermill": {
     "duration": 0.332518,
     "end_time": "2022-12-11T01:35:07.673216",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.340698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images_tensor(t.sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0bc281",
   "metadata": {
    "papermill": {
     "duration": 0.014912,
     "end_time": "2022-12-11T01:35:07.709923",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.695011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop\n",
    "\n",
    "We need to modify our train loop to read images from the data loader and not from memory. Images will no longer fit into memory (at least on Kaggle).\n",
    "\n",
    "We will do an optimization to speed up our calculation. Instead of reloading images and sending them to GPU again and again, we will pre-allocate memory on GPU, copy images once, then use them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445490c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:07.740630Z",
     "iopub.status.busy": "2022-12-11T01:35:07.740252Z",
     "iopub.status.idle": "2022-12-11T01:35:07.747095Z",
     "shell.execute_reply": "2022-12-11T01:35:07.746367Z"
    },
    "papermill": {
     "duration": 0.024958,
     "end_time": "2022-12-11T01:35:07.749264",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.724306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_validation_loss(model, valid_loader, criterion, device, kl_factor):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    mse_loss = 0\n",
    "    kl_loss = 0\n",
    "    image_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            output, z_mean, log_var = model(images)\n",
    "            cur_loss, cur_r_loss, cur_kl_loss = criterion(output, images, kl_factor, z_mean, log_var)\n",
    " \n",
    "            batch_size = images.shape[0] # Can have an incomlete batch at the end\n",
    "            del images # to help free memory on GPU\n",
    "\n",
    "            total_loss += cur_loss * batch_size  # recover sum from the mean return by the loss function.\n",
    "            mse_loss += cur_r_loss * batch_size  # we'll need it to correctly calcualte the global mean.\n",
    "            kl_loss += cur_kl_loss * batch_size\n",
    "            \n",
    "            image_count += batch_size\n",
    "            \n",
    "    return total_loss / image_count, mse_loss / image_count, kl_loss / image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ab606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:07.789941Z",
     "iopub.status.busy": "2022-12-11T01:35:07.789820Z",
     "iopub.status.idle": "2022-12-11T01:35:07.859033Z",
     "shell.execute_reply": "2022-12-11T01:35:07.858441Z"
    },
    "papermill": {
     "duration": 0.088461,
     "end_time": "2022-12-11T01:35:07.862398",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.773937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_count(image_folder):\n",
    "    result = 0\n",
    "    for _ in os.listdir(image_folder):\n",
    "        result += 1\n",
    "    return result\n",
    "\n",
    "t.image_count = image_count(t.image_folder)\n",
    "t.image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf34a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:07.916969Z",
     "iopub.status.busy": "2022-12-11T01:35:07.916099Z",
     "iopub.status.idle": "2022-12-11T01:35:07.939328Z",
     "shell.execute_reply": "2022-12-11T01:35:07.938580Z"
    },
    "papermill": {
     "duration": 0.044436,
     "end_time": "2022-12-11T01:35:07.941163",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.896727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "def train(model, n_epochs, train_loader, opt, report_each_nth_batch, start_lr,\n",
    "         valid_loader):\n",
    "    print(\"Running on: \", t.device)\n",
    "    print(\"Model name:\", model.model_file_name)\n",
    "    print(\"Model parameters:\", sum(p.numel() for p in t.model.parameters()))\n",
    "    print()\n",
    "    print(f\"Batch size: {train_loader.batch_size}, Epochs: {n_epochs}\")\n",
    "    print(\"Epoch, Batch num, Train loss, Valid Loss, MSE loss, KL loss, KL Factor, Total epochs, Train time, Total train time, LR\")\n",
    "\n",
    "    log_dict = {\n",
    "        'batch_train_loss': [], \n",
    "        'batch_mse_loss': [], \n",
    "        'batch_kl_div': [], \n",
    "        'valid_loss': []\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    batch_num = 0\n",
    "    kl_factor = 1\n",
    "    epoch = 0 \n",
    "    train_loss = -1\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        opt, \n",
    "        mode='min',\n",
    "        factor=0.1, \n",
    "        patience=3, \n",
    "        threshold=1, \n",
    "        threshold_mode='abs') \n",
    "    \n",
    "    while model._total_epochs < n_epochs:\n",
    "        epoch += 1\n",
    "        # Start of epoch training\n",
    "        for i, data in enumerate(train_loader):\n",
    "            image_batch, labels_smile = data\n",
    "            model.start_training()\n",
    "\n",
    "            image_batch = image_batch.to(t.device, non_blocking=True)\n",
    "            \n",
    "            # Train model\n",
    "            output, z_mean, log_var = model(image_batch)\n",
    "            loss, r_loss, kl_div = vae_loss(output, image_batch, kl_factor, z_mean, log_var)\n",
    "            \n",
    "            log_dict['batch_train_loss'].append(loss.item())\n",
    "            log_dict['batch_mse_loss'].append(r_loss.item())\n",
    "            log_dict['batch_kl_div'].append(kl_div.item())\n",
    "                    \n",
    "            model.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            \n",
    "            batch_num += 1\n",
    "            \n",
    "            if batch_num % report_each_nth_batch == 0:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    train_loss = loss.item()\n",
    "                    # Validate\n",
    "                    total, r_loss, kl_div = calculate_validation_loss(model, valid_loader, vae_loss, t.device, kl_factor)\n",
    "                    model.end_training()\n",
    "                    print(f\"{epoch}, {batch_num}, {train_loss:.2f}, {total.item():.2f}, {r_loss.item():.2f},\", \n",
    "                          f\"{kl_div.item():.2f}, {kl_factor}, {model._total_epochs},\",\n",
    "                          f\"{timedelta(seconds=time.time() - start_time)},\",\n",
    "                          f\"{model.training_timedelta()}, {start_lr}\")\n",
    "                    model.train()\n",
    "                    model.start_training()\n",
    "        # End of epoch training        \n",
    "        lr_scheduler.step(loss)\n",
    "        model.add_epochs(1)\n",
    "        torch.save(t.model, model.model_file_name)\n",
    "    model.end_training()\n",
    "    model.eval()\n",
    "    # Validate\n",
    "    with torch.no_grad():\n",
    "        total, r_loss, kl_div = calculate_validation_loss(model, valid_loader, vae_loss, t.device, kl_factor)\n",
    "        print(f\"{epoch}, {batch_num}, {train_loss:.2f}, {total.item():.2f}, {r_loss.item():.2f},\", \n",
    "              f\"{kl_div.item():.2f},\",\n",
    "              f\"{model._total_epochs}, {timedelta(seconds=time.time() - start_time)},\",\n",
    "              f\"{model.training_timedelta()},\",\n",
    "              f\"{start_lr}\")\n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69958ff",
   "metadata": {
    "papermill": {
     "duration": 0.015102,
     "end_time": "2022-12-11T01:35:07.978485",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.963383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef8114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T01:35:08.010586Z",
     "iopub.status.busy": "2022-12-11T01:35:08.009882Z",
     "iopub.status.idle": "2022-12-11T06:57:35.963631Z",
     "shell.execute_reply": "2022-12-11T06:57:35.963201Z"
    },
    "papermill": {
     "duration": 19347.9713,
     "end_time": "2022-12-11T06:57:35.964863",
     "exception": false,
     "start_time": "2022-12-11T01:35:07.993563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t.opt = torch.optim.Adam(t.model.parameters(), lr=1e-4)\n",
    "\n",
    "log_dict = train(\n",
    "    model = t.model, \n",
    "    n_epochs = 20, \n",
    "    train_loader  = t.train_loader, \n",
    "    opt = t.opt, \n",
    "    report_each_nth_batch = 2000,\n",
    "    start_lr = 1e-4,\n",
    "    valid_loader=t.valid_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85371197",
   "metadata": {
    "papermill": {
     "duration": 0.037137,
     "end_time": "2022-12-11T06:57:36.054165",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.017028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804121f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:36.111080Z",
     "iopub.status.busy": "2022-12-11T06:57:36.110691Z",
     "iopub.status.idle": "2022-12-11T06:57:36.134634Z",
     "shell.execute_reply": "2022-12-11T06:57:36.133749Z"
    },
    "papermill": {
     "duration": 0.055226,
     "end_time": "2022-12-11T06:57:36.136631",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.081405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load saved model with the most recent timestamp.\n",
    "t.model_file = [f for f in sorted(os.listdir()) if f.startswith(\"faces_vae_\")][-1]\n",
    "t.model = torch.load(t.model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099dcf4",
   "metadata": {
    "papermill": {
     "duration": 0.027245,
     "end_time": "2022-12-11T06:57:36.202598",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.175353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Check the Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b730e6f",
   "metadata": {
    "papermill": {
     "duration": 0.027401,
     "end_time": "2022-12-11T06:57:36.257275",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.229874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Original images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da538235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:36.313159Z",
     "iopub.status.busy": "2022-12-11T06:57:36.312978Z",
     "iopub.status.idle": "2022-12-11T06:57:36.543256Z",
     "shell.execute_reply": "2022-12-11T06:57:36.542602Z"
    },
    "papermill": {
     "duration": 0.272205,
     "end_time": "2022-12-11T06:57:36.556749",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.284544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.i = 0\n",
    "plot_images_tensor(t.sample_images[t.i:t.i+12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c7e7c8",
   "metadata": {
    "papermill": {
     "duration": 0.0291,
     "end_time": "2022-12-11T06:57:36.627963",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.598863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reconstructed images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3594b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:36.688450Z",
     "iopub.status.busy": "2022-12-11T06:57:36.687974Z",
     "iopub.status.idle": "2022-12-11T06:57:36.914862Z",
     "shell.execute_reply": "2022-12-11T06:57:36.914206Z"
    },
    "papermill": {
     "duration": 0.268718,
     "end_time": "2022-12-11T06:57:36.926086",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.657368",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images_tensor(t.model(t.sample_images[t.i : t.i+12])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6391938e",
   "metadata": {
    "papermill": {
     "duration": 0.030879,
     "end_time": "2022-12-11T06:57:37.000822",
     "exception": false,
     "start_time": "2022-12-11T06:57:36.969943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989668a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:37.065390Z",
     "iopub.status.busy": "2022-12-11T06:57:37.064835Z",
     "iopub.status.idle": "2022-12-11T06:57:37.070335Z",
     "shell.execute_reply": "2022-12-11T06:57:37.069361Z"
    },
    "papermill": {
     "duration": 0.039517,
     "end_time": "2022-12-11T06:57:37.071668",
     "exception": false,
     "start_time": "2022-12-11T06:57:37.032151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = Object()\n",
    "a.model = t.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbaaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:37.138942Z",
     "iopub.status.busy": "2022-12-11T06:57:37.138408Z",
     "iopub.status.idle": "2022-12-11T06:57:39.286893Z",
     "shell.execute_reply": "2022-12-11T06:57:39.286225Z"
    },
    "papermill": {
     "duration": 2.182563,
     "end_time": "2022-12-11T06:57:39.288206",
     "exception": false,
     "start_time": "2022-12-11T06:57:37.105643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a.emb = None\n",
    "    image_count = 1024\n",
    "    for images, _ in t.valid_loader:\n",
    "        images = images.to(t.device)\n",
    "        emb = a.model.encode(images)[0]\n",
    "        emb = emb.detach().cpu().numpy()\n",
    "        if a.emb is None:\n",
    "            a.emb = emb\n",
    "        else:\n",
    "            a.emb = np.append(a.emb, emb, axis=0)\n",
    "        image_count -= images.shape[0]\n",
    "        del images\n",
    "        if image_count <= 0:\n",
    "            break\n",
    "a.valid_emb = a.emb\n",
    "torch.cuda.empty_cache()\n",
    "a.valid_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f4729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:39.358125Z",
     "iopub.status.busy": "2022-12-11T06:57:39.357736Z",
     "iopub.status.idle": "2022-12-11T06:57:39.365905Z",
     "shell.execute_reply": "2022-12-11T06:57:39.364995Z"
    },
    "papermill": {
     "duration": 0.043855,
     "end_time": "2022-12-11T06:57:39.367331",
     "exception": false,
     "start_time": "2022-12-11T06:57:39.323476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.valid_emb[:, 4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f52096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:39.434666Z",
     "iopub.status.busy": "2022-12-11T06:57:39.433688Z",
     "iopub.status.idle": "2022-12-11T06:57:40.206080Z",
     "shell.execute_reply": "2022-12-11T06:57:40.205362Z"
    },
    "papermill": {
     "duration": 0.811652,
     "end_time": "2022-12-11T06:57:40.212764",
     "exception": false,
     "start_time": "2022-12-11T06:57:39.401112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        x = a.valid_emb[:, i]\n",
    "        y = a.valid_emb[:, 10 + j]\n",
    "        ax = fig.axes[i * 4 + j]\n",
    "        ax.set_ylim(-5, 5)\n",
    "        ax.set_xlim(-5, 5)\n",
    "        ax.scatter(x, y, s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a3cb5",
   "metadata": {
    "papermill": {
     "duration": 0.032293,
     "end_time": "2022-12-11T06:57:40.291171",
     "exception": false,
     "start_time": "2022-12-11T06:57:40.258878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sample Images from VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699c717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:40.356759Z",
     "iopub.status.busy": "2022-12-11T06:57:40.356332Z",
     "iopub.status.idle": "2022-12-11T06:57:40.362481Z",
     "shell.execute_reply": "2022-12-11T06:57:40.361914Z"
    },
    "papermill": {
     "duration": 0.042832,
     "end_time": "2022-12-11T06:57:40.365466",
     "exception": false,
     "start_time": "2022-12-11T06:57:40.322634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.randn(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11139639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:40.446347Z",
     "iopub.status.busy": "2022-12-11T06:57:40.446043Z",
     "iopub.status.idle": "2022-12-11T06:57:40.450477Z",
     "shell.execute_reply": "2022-12-11T06:57:40.449803Z"
    },
    "papermill": {
     "duration": 0.040555,
     "end_time": "2022-12-11T06:57:40.453884",
     "exception": false,
     "start_time": "2022-12-11T06:57:40.413329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_images_from_vae(model, emb_size, device, num_images):\n",
    "    with torch.no_grad():\n",
    "        rand_emb = torch.randn(num_images, emb_size).to(device)\n",
    "        sampled_images = model.decoder(rand_emb)\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=num_images, figsize=(10, 3), sharey=True)\n",
    "        for ax, im in zip(axes, sampled_images):\n",
    "            im_np = im.detach().cpu().numpy()\n",
    "            im_np = np.transpose(im_np, (1, 2, 0))\n",
    "            ax.imshow(im_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ba7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:40.552942Z",
     "iopub.status.busy": "2022-12-11T06:57:40.552383Z",
     "iopub.status.idle": "2022-12-11T06:57:43.239929Z",
     "shell.execute_reply": "2022-12-11T06:57:43.238906Z"
    },
    "papermill": {
     "duration": 2.722609,
     "end_time": "2022-12-11T06:57:43.241384",
     "exception": false,
     "start_time": "2022-12-11T06:57:40.518775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in range(6):\n",
    "    sample_images_from_vae(t.model, 200, t.device, 10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b97e5",
   "metadata": {
    "papermill": {
     "duration": 0.035698,
     "end_time": "2022-12-11T06:57:43.314491",
     "exception": false,
     "start_time": "2022-12-11T06:57:43.278793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Latent Space Vector Algebra\n",
    "\n",
    "1. Load 512 images with no smile.\n",
    "   1. Get their embedddings.\n",
    "   1. Calculate average.\n",
    "1. Load 512 images with smile.\n",
    "   1. Get their embedddings.\n",
    "   1. Calculate average.\n",
    "1. Calculate the difference between mean_smile - mean_no_smile. We'll get the \"add smile\" vector.\n",
    "\n",
    "\n",
    "#### Q. How do we add a smile to an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8feef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:43.388252Z",
     "iopub.status.busy": "2022-12-11T06:57:43.387139Z",
     "iopub.status.idle": "2022-12-11T06:57:43.393848Z",
     "shell.execute_reply": "2022-12-11T06:57:43.392865Z"
    },
    "papermill": {
     "duration": 0.045445,
     "end_time": "2022-12-11T06:57:43.395405",
     "exception": false,
     "start_time": "2022-12-11T06:57:43.349960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.train_loader = torch.utils.data.DataLoader(\n",
    "    t.train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be08e8",
   "metadata": {
    "papermill": {
     "duration": 0.035432,
     "end_time": "2022-12-11T06:57:43.469854",
     "exception": false,
     "start_time": "2022-12-11T06:57:43.434422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculate the \"Smile\" Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af5e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:43.542830Z",
     "iopub.status.busy": "2022-12-11T06:57:43.542309Z",
     "iopub.status.idle": "2022-12-11T06:57:44.458641Z",
     "shell.execute_reply": "2022-12-11T06:57:44.457216Z"
    },
    "papermill": {
     "duration": 0.957026,
     "end_time": "2022-12-11T06:57:44.462313",
     "exception": false,
     "start_time": "2022-12-11T06:57:43.505287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.image_count = 512\n",
    "a.smile_emb = torch.zeros(512, 3, 128, 128)\n",
    "a.no_smile_emb = torch.zeros(512, 3, 128, 128)\n",
    "a.images_no_smile = torch.zeros(512, 3, 128, 128)\n",
    "a.images_smile = torch.zeros(512, 3, 128, 128)\n",
    "\n",
    "\n",
    "a.count_smile = 0\n",
    "a.count_no_smile = 0\n",
    "a.iter = a.train_loader.__iter__();\n",
    "a.classes = a.train_loader.dataset.smile_to_int\n",
    "\n",
    "while a.count_smile < a.image_count or a.count_no_smile < a.image_count:\n",
    "    images, labels = next(a.iter)\n",
    "    for im, lbl in zip(images, labels):\n",
    "        if lbl == a.classes['smile'] and a.count_smile < a.image_count:\n",
    "            a.images_smile[a.count_smile, :, :, :] = im\n",
    "            a.count_smile += 1\n",
    "        elif a.count_no_smile < a.image_count:\n",
    "            a.images_no_smile[a.count_no_smile, :, :, :] = im\n",
    "            a.count_no_smile += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c59df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:44.571685Z",
     "iopub.status.busy": "2022-12-11T06:57:44.571389Z",
     "iopub.status.idle": "2022-12-11T06:57:45.084839Z",
     "shell.execute_reply": "2022-12-11T06:57:45.084053Z"
    },
    "papermill": {
     "duration": 0.567147,
     "end_time": "2022-12-11T06:57:45.098371",
     "exception": false,
     "start_time": "2022-12-11T06:57:44.531224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images_tensor(a.images_smile[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c90e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:45.189123Z",
     "iopub.status.busy": "2022-12-11T06:57:45.188808Z",
     "iopub.status.idle": "2022-12-11T06:57:45.405564Z",
     "shell.execute_reply": "2022-12-11T06:57:45.404909Z"
    },
    "papermill": {
     "duration": 0.262652,
     "end_time": "2022-12-11T06:57:45.411808",
     "exception": false,
     "start_time": "2022-12-11T06:57:45.149156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images_tensor(a.images_no_smile[0: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889d4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:45.501062Z",
     "iopub.status.busy": "2022-12-11T06:57:45.500503Z",
     "iopub.status.idle": "2022-12-11T06:57:45.590803Z",
     "shell.execute_reply": "2022-12-11T06:57:45.589808Z"
    },
    "papermill": {
     "duration": 0.137567,
     "end_time": "2022-12-11T06:57:45.593879",
     "exception": false,
     "start_time": "2022-12-11T06:57:45.456312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a.smile_emb = a.model.encode(a.images_smile.to(t.device))[0]\n",
    "    a.no_smile_emb = a.model.encode(a.images_no_smile.to(t.device))[0]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c2a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:45.701763Z",
     "iopub.status.busy": "2022-12-11T06:57:45.701078Z",
     "iopub.status.idle": "2022-12-11T06:57:45.706381Z",
     "shell.execute_reply": "2022-12-11T06:57:45.705419Z"
    },
    "papermill": {
     "duration": 0.052756,
     "end_time": "2022-12-11T06:57:45.709214",
     "exception": false,
     "start_time": "2022-12-11T06:57:45.656458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.smile_vec = torch.mean(a.smile_emb, axis=0) - torch.mean(a.no_smile_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00df69b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:45.812928Z",
     "iopub.status.busy": "2022-12-11T06:57:45.812733Z",
     "iopub.status.idle": "2022-12-11T06:57:45.829580Z",
     "shell.execute_reply": "2022-12-11T06:57:45.828746Z"
    },
    "papermill": {
     "duration": 0.062469,
     "end_time": "2022-12-11T06:57:45.831096",
     "exception": false,
     "start_time": "2022-12-11T06:57:45.768627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.smile_vec.shape, a.smile_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44a839",
   "metadata": {
    "papermill": {
     "duration": 0.042243,
     "end_time": "2022-12-11T06:57:45.919499",
     "exception": false,
     "start_time": "2022-12-11T06:57:45.877256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Add a Smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7aa4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:46.006470Z",
     "iopub.status.busy": "2022-12-11T06:57:46.005481Z",
     "iopub.status.idle": "2022-12-11T06:57:46.017174Z",
     "shell.execute_reply": "2022-12-11T06:57:46.015973Z"
    },
    "papermill": {
     "duration": 0.05889,
     "end_time": "2022-12-11T06:57:46.020069",
     "exception": false,
     "start_time": "2022-12-11T06:57:45.961179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.test_no_smile_images = a.images_no_smile[14:24]\n",
    "with torch.no_grad():\n",
    "    a.test_no_smile = a.model.encode(a.test_no_smile_images.to(t.device))[0]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73413b58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:46.122354Z",
     "iopub.status.busy": "2022-12-11T06:57:46.121606Z",
     "iopub.status.idle": "2022-12-11T06:57:46.340015Z",
     "shell.execute_reply": "2022-12-11T06:57:46.339009Z"
    },
    "papermill": {
     "duration": 0.265827,
     "end_time": "2022-12-11T06:57:46.343210",
     "exception": false,
     "start_time": "2022-12-11T06:57:46.077383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images_tensor(a.test_no_smile_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928e92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:46.435392Z",
     "iopub.status.busy": "2022-12-11T06:57:46.435073Z",
     "iopub.status.idle": "2022-12-11T06:57:46.652212Z",
     "shell.execute_reply": "2022-12-11T06:57:46.651400Z"
    },
    "papermill": {
     "duration": 0.275866,
     "end_time": "2022-12-11T06:57:46.664674",
     "exception": false,
     "start_time": "2022-12-11T06:57:46.388808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a.test_smile_images = a.model.decoder(a.test_no_smile)\n",
    "torch.cuda.empty_cache()\n",
    "plot_images_tensor(a.test_smile_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1337b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:46.774683Z",
     "iopub.status.busy": "2022-12-11T06:57:46.773657Z",
     "iopub.status.idle": "2022-12-11T06:57:46.782337Z",
     "shell.execute_reply": "2022-12-11T06:57:46.781396Z"
    },
    "papermill": {
     "duration": 0.059646,
     "end_time": "2022-12-11T06:57:46.783690",
     "exception": false,
     "start_time": "2022-12-11T06:57:46.724044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.test_smile = a.test_no_smile  + 1.5 * a.smile_vec\n",
    "a.test_smile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5515405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T06:57:46.901789Z",
     "iopub.status.busy": "2022-12-11T06:57:46.901477Z",
     "iopub.status.idle": "2022-12-11T06:57:47.367601Z",
     "shell.execute_reply": "2022-12-11T06:57:47.366937Z"
    },
    "papermill": {
     "duration": 0.518872,
     "end_time": "2022-12-11T06:57:47.372269",
     "exception": false,
     "start_time": "2022-12-11T06:57:46.853397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    a.test_smile_images = a.model.decoder(a.test_smile)\n",
    "torch.cuda.empty_cache()\n",
    "plot_images_tensor(a.test_smile_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac0420",
   "metadata": {
    "papermill": {
     "duration": 0.047757,
     "end_time": "2022-12-11T06:57:47.469105",
     "exception": false,
     "start_time": "2022-12-11T06:57:47.421348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19371.924146,
   "end_time": "2022-12-11T06:57:50.479643",
   "environment_variables": {},
   "exception": null,
   "input_path": "Faces VAE.ipynb",
   "output_path": "output-faces-vae.ipynb",
   "parameters": {},
   "start_time": "2022-12-11T01:34:58.555497",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.261px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
